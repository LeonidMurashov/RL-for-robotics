{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baselines.common.vec_env.subproc_vec_env import SubprocVecEnv\n",
    "from baselines.common.vec_env.dummy_vec_env import DummyVecEnv\n",
    "from tqdm import tqdm_notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import copy\n",
    "import random\n",
    "import gym\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_net(name1, name2):\n",
    "    variables = tf.trainable_variables()\n",
    "    for var1 in variables:\n",
    "        if name2+\"/\" in var1.name:\n",
    "            trained_var = [var2 for var2 in tf.trainable_variables() if var2.op.name in str.replace(var1.name, name2+\"/\", name1+\"/\")][0]\n",
    "            value = sess.run(trained_var)\n",
    "            sess.run(tf.assign(var1, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class QualityNet:\n",
    "    def __init__(self, **kwargs):\n",
    "        with tf.variable_scope(kwargs.get(\"net_name\")+\"/\"):\n",
    "            self.action_space_size = kwargs.get(\"action_space_size\", 3)\n",
    "            self.observation_space_size = kwargs.get(\"observation_space_size\", 2)\n",
    "            state_queue_size = kwargs.get(\"state_queue_size\", 1) #TODO: set qsize from QLearning Class\n",
    "\n",
    "            layers_config = kwargs.get(\"layers_config\", (self.action_space_size + state_queue_size*self.observation_space_size, 32)) \n",
    "\n",
    "            self.input_state = tf.placeholder(tf.float32, shape=[None, state_queue_size, self.observation_space_size], name=\"input_state\")\n",
    "            self.flattened_state = tf.reshape(self.input_state, [-1, self.observation_space_size * state_queue_size])\n",
    "            self.input_action = tf.placeholder(tf.int32, shape=[None], name=\"input_action\")\n",
    "            input_action_one_hot = tf.one_hot(self.input_action, depth=self.action_space_size)\n",
    "            \n",
    "            self.input_data = tf.concat([self.flattened_state, input_action_one_hot], 1)\n",
    "            \n",
    "            self.input_layer = tf.layers.dense(self.input_data, units=layers_config[0], activation='relu')\n",
    "            self.hidden_layer = tf.layers.dense(self.input_layer, units=layers_config[1], activation = 'relu')\n",
    "            self.output_layer = tf.layers.dense(self.hidden_layer, units=1)\n",
    "            \n",
    "            self.exp_value = tf.placeholder(tf.float32, name=\"exp_value\") #  shape=[None] WTF???\n",
    "            self.loss = tf.losses.mean_squared_error(self.exp_value, self.output_layer)\n",
    "            \n",
    "            optimizer = tf.train.RMSPropOptimizer(0.1)\n",
    "            self.train_op = optimizer.minimize(self.loss)\n",
    "        \n",
    "    def train(self, batch):\n",
    "        global sess\n",
    "        input_state = [batch[:, 0][i] for i in range(len(batch))]\n",
    "        input_action = batch[:, 1]\n",
    "        \n",
    "        _, loss = sess.run((self.train_op, self.loss), \n",
    "                           feed_dict = {\n",
    "                                self.input_state: input_state,\n",
    "                                self.input_action: input_action,\n",
    "                                self.exp_value: batch[:, 4],\n",
    "                            })\n",
    "        return loss\n",
    "        \n",
    "    def feed_forward(self, states_list, action):\n",
    "        global sess\n",
    "        output = sess.run((self.output_layer), feed_dict = {self.input_state: states_list, self.input_action: action})\n",
    "        return output\n",
    "    \n",
    "    def predict_actions(self, state_queues):\n",
    "        states_input = np.repeat(np.array(state_queues), repeats=self.action_space_size, axis=0)\n",
    "        actions_input = np.tile(range(self.action_space_size), len(state_queues))\n",
    "        \n",
    "        qvalues = self.feed_forward(states_input, actions_input)\n",
    "        qvalues = qvalues.reshape(len(qvalues) // self.action_space_size, self.action_space_size)  \n",
    "        return np.argmax(qvalues, axis=1)\n",
    "\n",
    "    def get_max_q(self, batch):\n",
    "        states_input = np.repeat(batch[:, 3], repeats=self.action_space_size, axis=0)\n",
    "        actions_input = np.tile(np.arange(self.action_space_size), len(batch))\n",
    "        qvalues = self.feed_forward(np.array(states_input.tolist()), actions_input)\n",
    "        qvalues = qvalues.reshape(len(qvalues) // self.action_space_size, self.action_space_size) \n",
    "        return np.max(qvalues, axis=1)\n",
    "        \n",
    "class QLearning:\n",
    "    def __init__(self, env_name, **kwargs):\n",
    "        self.stochastic_action_likelihood = kwargs.get(\"stoch_act_ch\", 0.6)\n",
    "        self.stochastic_action_likelihood_d = kwargs.get(\"stoch_act_ch_d\", 0.001) #TODO: adaptive stoch_action_l_d; endpoint: 0.1\n",
    "        self.discount = kwargs.get(\"discount\", 0.99)\n",
    "        self.rewards = []\n",
    "\n",
    "        self.nproc = kwargs.get(\"nproc\", 30)\n",
    "        self.envs = DummyVecEnv([self.make_env(env_name, seed) for seed in range(self.nproc)]) #Dummy\n",
    "        \n",
    "        # This code gets action and observation space sizes for 1D tasks\n",
    "        self.action_space_size = self.envs.action_space.n if isinstance(self.envs.action_space, gym.spaces.discrete.Discrete) else self.envs.action_space.shape[0]\n",
    "        self.observation_space_size = self.envs.observation_space.n if isinstance(self.envs.observation_space, gym.spaces.discrete.Discrete) else self.envs.observation_space.shape[0]\n",
    "        \n",
    "        env_data = {\n",
    "            \"observation_space_size\": self.observation_space_size,\n",
    "            \"action_space_size\": self.action_space_size,\n",
    "        }\n",
    "        \n",
    "        prediction_net_params = kwargs.get(\"prediction_net_params\", {})\n",
    "        prediction_net_params[\"net_name\"] = \"prediction_net\"\n",
    "        prediction_net_params.update(env_data)\n",
    "        self.prediction_net = QualityNet(**prediction_net_params)\n",
    "        \n",
    "        train_net_params = kwargs.get(\"train_net_params\", {})\n",
    "        train_net_params[\"net_name\"] = \"train_net\"\n",
    "        train_net_params.update(env_data)\n",
    "        self.train_net = QualityNet(**train_net_params)\n",
    "        \n",
    "    def update_state(self, state_queue, val):\n",
    "        state_queue.pop()\n",
    "        state_queue.insert(0, val)\n",
    "\n",
    "    def batch_generator(self, state_queue_size, batch_size, history_size):\n",
    "        \"\"\"\n",
    "            history[0] = queue of four last states\n",
    "            history[1] = action\n",
    "            history[2] = reward\n",
    "            history[3] = states queue with new state\n",
    "        \"\"\"\n",
    "        self.rewards = []\n",
    "        qstates = [[np.random.sample(len(self.envs.observation_space.sample())) for _ in range(state_queue_size)] for _ in range(self.nproc)] #observation_space_size refactor\n",
    "        trajectories = [np.empty((0, 4)) for _ in range(self.nproc)]\n",
    "        \n",
    "        history = np.empty((0, 5))\n",
    "        observations = self.envs.reset()\n",
    "        for pid in range(self.nproc):\n",
    "            self.update_state(qstates[pid], observations[pid])\n",
    "\n",
    "        while True:\n",
    "            history = history[batch_size:]\n",
    "            while len(history) < history_size:\n",
    "                if random.random() < self.stochastic_action_likelihood:\n",
    "                    actions = np.stack([self.envs.action_space.sample() for _ in range(self.nproc)]) # test\n",
    "                else:\n",
    "                    actions = self.prediction_net.predict_actions(qstates)\n",
    "                observations, rewards, dones, _ = self.envs.step(actions)\n",
    "\n",
    "                for pid in range(self.nproc):\n",
    "                    new_state = copy.deepcopy(qstates[pid])\n",
    "                    self.update_state(new_state, observations[pid])\n",
    "                    \n",
    "                    trajectories[pid] = np.vstack((trajectories[pid], [qstates[pid], actions[pid], rewards[pid], new_state]))\n",
    "                    \n",
    "                    if dones[pid]:\n",
    "                        qvalues = self.prediction_net.get_max_q(trajectories[pid][:-1])\n",
    "                        qvalues *= self.discount\n",
    "                        qvalues = qvalues + trajectories[pid][:-1][:, 2]\n",
    "                        qvalues = np.append(qvalues, rewards[pid])\n",
    "                        new_history = np.hstack((trajectories[pid], np.expand_dims(qvalues, axis=-1)))\n",
    "                        \n",
    "                        self.rewards.append(trajectories[pid][:-1][:, 2].sum() + rewards[pid])\n",
    "                        trajectories[pid] = np.empty((0, 4))\n",
    "                        history = np.vstack((history, new_history))\n",
    "                                    \n",
    "            np.random.shuffle(history)\n",
    "            yield history[np.random.choice(history.shape[0], size=batch_size), :]\n",
    "\n",
    "    def make_env(self, env_id, seed):\n",
    "        nproc = self.nproc\n",
    "        def _f():\n",
    "\n",
    "            env = gym.make(env_id)\n",
    "            env.seed(seed)\n",
    "\n",
    "            # Desync environments\n",
    "            env.reset()\n",
    "            for i in range(int(env.spec.max_episode_steps*seed//nproc)):\n",
    "                env.step(env.action_space.sample())\n",
    "            return env\n",
    "        return _f\n",
    "    \n",
    "    def run(self, iterations=10000, batch_size=64, state_window=1, update_net_period=50, history_size=500):\n",
    "        self.update_net_period = update_net_period\n",
    "        loss_list = list()\n",
    "        self.batch_gen = self.batch_generator(state_window, batch_size, history_size)\n",
    "        \n",
    "        for i in range(10):\n",
    "            next(self.batch_gen)\n",
    "        \n",
    "        for i in tqdm_notebook(range(iterations)):\n",
    "            batch = next(self.batch_gen)\n",
    "            \n",
    "            loss = self.train_net.train(batch)\n",
    "            loss_list.append(loss)\n",
    "            \n",
    "            if i % self.update_net_period == 0:\n",
    "                copy_net(\"train_net\", \"prediction_net\")\n",
    "            \n",
    "            self.stochastic_action_likelihood -= self.stochastic_action_likelihood_d\n",
    "        plt.plot(self.rewards)  \n",
    "        \n",
    "    def test(self, env_name):\n",
    "        print(sess.run((self.prediction_net.output_layer), feed_dict={\n",
    "            self.prediction_net.input_state: [[[0, 0]], [[0, 0]], [[0,0]]],\n",
    "            self.prediction_net.input_action: [0, 1, 2],\n",
    "        }))\n",
    "        \n",
    "        env = gym.make(env_name)\n",
    "        observation = env.reset()\n",
    "        \n",
    "        trained_batch = next(self.batch_gen) \n",
    "        print(\"TRAINED BATCH:\", trained_batch)\n",
    "        \n",
    "        for i in range(10000):\n",
    "            try:\n",
    "                action = self.prediction_net.predict_actions([[observation]])\n",
    "                observation, reward, done, _ = env.step(action[0])    \n",
    "                env.render()\n",
    "                if done:\n",
    "                    observation = env.reset()\n",
    "            except KeyboardInterrupt:\n",
    "                env.close()\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0715 17:51:42.646511  1092 deprecation.py:323] From <ipython-input-4-44211c7da1ad>:17: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "W0715 17:51:42.671519  1092 deprecation.py:506] From C:\\Users\\suriknik\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0715 17:51:43.337502  1092 deprecation.py:323] From C:\\Users\\suriknik\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\losses\\losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0715 17:51:43.522508  1092 deprecation.py:506] From C:\\Users\\suriknik\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed5ed914d2e6413186740f1d519c52d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ql = QLearning(\"MountainCar-v0\")\n",
    "\n",
    "sess.run(tf.local_variables_initializer())\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "ql.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-52.20361]\n",
      " [-52.20361]\n",
      " [-52.20361]]\n",
      "TRAINED BATCH: [[list([array([-0.44839054,  0.        ], dtype=float32)]) 0 -1.0\n",
      "  list([array([-0.57718706, -0.01035995], dtype=float32)])\n",
      "  -52.63603210449219]\n",
      " [list([array([-0.43117407,  0.        ], dtype=float32)]) 0 -1.0\n",
      "  list([array([-0.68254787,  0.00653965], dtype=float32)])\n",
      "  -52.63603210449219]\n",
      " [list([array([-0.4474817,  0.       ], dtype=float32)]) 0 -1.0\n",
      "  list([array([-0.57657194, -0.01165291], dtype=float32)])\n",
      "  -52.63603210449219]\n",
      " [list([array([-0.45796514,  0.        ], dtype=float32)]) 0 -1.0\n",
      "  list([array([-0.48805776, -0.00199165], dtype=float32)])\n",
      "  -52.63603210449219]\n",
      " [list([array([-0.5552024,  0.       ], dtype=float32)]) 0 -1.0\n",
      "  list([array([-0.5819099 ,  0.01035775], dtype=float32)])\n",
      "  -52.63603210449219]\n",
      " [list([array([-0.5463389,  0.       ], dtype=float32)]) 0 -1.0\n",
      "  list([array([-0.5888504 ,  0.01758138], dtype=float32)])\n",
      "  -52.63603210449219]\n",
      " [list([array([-0.46078435,  0.        ], dtype=float32)]) 0 -1.0\n",
      "  list([array([-0.7221061 , -0.01208226], dtype=float32)])\n",
      "  -52.370574951171875]\n",
      " [list([array([-0.4629486,  0.       ], dtype=float32)]) 0 -1.0\n",
      "  list([array([-0.7155132 , -0.00451695], dtype=float32)])\n",
      "  -52.63603210449219]\n",
      " [list([array([-0.43117407,  0.        ], dtype=float32)]) 0 -1.0\n",
      "  list([array([-0.7686974 , -0.00861538], dtype=float32)])\n",
      "  -52.370574951171875]\n",
      " [list([array([-0.45153373,  0.        ], dtype=float32)]) 0 -1.0\n",
      "  list([array([-0.75250334, -0.00856262], dtype=float32)])\n",
      "  -52.63603210449219]\n",
      " [list([array([-0.4629486,  0.       ], dtype=float32)]) 0 -1.0\n",
      "  list([array([-0.59208983,  0.00261293], dtype=float32)])\n",
      "  -52.63603210449219]\n",
      " [list([array([-0.5987869,  0.       ], dtype=float32)]) 0 -1.0\n",
      "  list([array([-0.6375354 , -0.00683311], dtype=float32)])\n",
      "  -52.63603210449219]\n",
      " [list([array([-0.54950947,  0.        ], dtype=float32)]) 0 -1.0\n",
      "  list([array([-0.72467947, -0.0150903 ], dtype=float32)])\n",
      "  -52.63603210449219]\n",
      " [list([array([-0.4971,  0.    ], dtype=float32)]) 0 -1.0\n",
      "  list([array([-0.7093899,  0.0087358], dtype=float32)])\n",
      "  -52.63603210449219]\n",
      " [list([array([-0.5740233,  0.       ], dtype=float32)]) 0 -1.0\n",
      "  list([array([-0.7281427 ,  0.01018553], dtype=float32)])\n",
      "  -52.370574951171875]\n",
      " [list([array([-0.43184012,  0.        ], dtype=float32)]) 0 -1.0\n",
      "  list([array([-0.87659186, -0.00694692], dtype=float32)])\n",
      "  -52.63603210449219]\n",
      " [list([array([-0.44946557,  0.        ], dtype=float32)]) 0 -1.0\n",
      "  list([array([-0.59842   , -0.00439415], dtype=float32)])\n",
      "  -52.63603210449219]\n",
      " [list([array([-0.576794,  0.      ], dtype=float32)]) 0 -1.0\n",
      "  list([array([-0.6290653 ,  0.01287641], dtype=float32)])\n",
      "  -52.63603210449219]\n",
      " [list([array([-0.5740233,  0.       ], dtype=float32)]) 0 -1.0\n",
      "  list([array([-0.8027432 ,  0.00487652], dtype=float32)])\n",
      "  -52.63603210449219]\n",
      " [list([array([-0.5357107,  0.       ], dtype=float32)]) 0 -1.0\n",
      "  list([array([-0.6293365 ,  0.01505898], dtype=float32)])\n",
      "  -52.63603210449219]\n",
      " [list([array([-0.43184012,  0.        ], dtype=float32)]) 0 -1.0\n",
      "  list([array([-0.8420141 , -0.01134867], dtype=float32)])\n",
      "  -52.63603210449219]\n",
      " [list([array([-0.48909995,  0.        ], dtype=float32)]) 0 -1.0\n",
      "  list([array([-0.70133674,  0.0050443 ], dtype=float32)])\n",
      "  -52.63603210449219]\n",
      " [list([array([-0.4971,  0.    ], dtype=float32)]) 0 -1.0\n",
      "  list([array([-0.62345487,  0.00757367], dtype=float32)])\n",
      "  -52.370574951171875]\n",
      " [list([array([-0.5357107,  0.       ], dtype=float32)]) 0 -1.0\n",
      "  list([array([-0.8464051 ,  0.00380278], dtype=float32)])\n",
      "  -52.63603210449219]\n",
      " [list([array([-0.5552024,  0.       ], dtype=float32)]) 0 -1.0\n",
      "  list([array([-0.74129355, -0.01039645], dtype=float32)])\n",
      "  -52.63603210449219]\n",
      " [list([array([-0.54950947,  0.        ], dtype=float32)]) 0 -1.0\n",
      "  list([array([-0.47701263, -0.00142113], dtype=float32)])\n",
      "  -52.63603210449219]\n",
      " [list([array([-0.5026329,  0.       ], dtype=float32)]) 0 -1.0\n",
      "  list([array([-0.867343  , -0.01310792], dtype=float32)])\n",
      "  -52.63603210449219]\n",
      " [list([array([-0.52102655,  0.        ], dtype=float32)]) 0 -1.0\n",
      "  list([array([-0.856519  ,  0.01170706], dtype=float32)])\n",
      "  -52.63603210449219]\n",
      " [list([array([-0.45153373,  0.        ], dtype=float32)]) 0 -1.0\n",
      "  list([array([-0.7794545 ,  0.00128326], dtype=float32)])\n",
      "  -52.370574951171875]\n",
      " [list([array([-0.43184012,  0.        ], dtype=float32)]) 0 -1.0\n",
      "  list([array([-0.7272103, -0.0172548], dtype=float32)])\n",
      "  -52.63603210449219]\n",
      " [list([array([-0.43677709,  0.        ], dtype=float32)]) 0 -1.0\n",
      "  list([array([-0.51220787, -0.01167164], dtype=float32)])\n",
      "  -52.63603210449219]\n",
      " [list([array([-0.44946557,  0.        ], dtype=float32)]) 0 -1.0\n",
      "  list([array([-7.4680561e-01, -1.3821929e-04], dtype=float32)])\n",
      "  -52.63603210449219]\n",
      " [list([array([-0.44946557,  0.        ], dtype=float32)]) 0 -1.0\n",
      "  list([array([-0.59765464, -0.00431687], dtype=float32)])\n",
      "  -52.63603210449219]\n",
      " [list([array([-0.48909995,  0.        ], dtype=float32)]) 0 -1.0\n",
      "  list([array([-0.62548465,  0.00553097], dtype=float32)])\n",
      "  -52.63603210449219]\n",
      " [list([array([-0.5987869,  0.       ], dtype=float32)]) 0 -1.0\n",
      "  list([array([-0.730081  ,  0.00421248], dtype=float32)])\n",
      "  -52.63603210449219]\n",
      " [list([array([-0.44946557,  0.        ], dtype=float32)]) 0 -1.0\n",
      "  list([array([-5.7786566e-01,  1.9866138e-04], dtype=float32)])\n",
      "  -52.63603210449219]\n",
      " [list([array([-0.4028963,  0.       ], dtype=float32)]) 0 -1.0\n",
      "  list([array([-0.8176091 ,  0.00964645], dtype=float32)])\n",
      "  -52.370574951171875]\n",
      " [list([array([-0.4623231,  0.       ], dtype=float32)]) 0 -1.0\n",
      "  list([array([-0.5582209 , -0.00162761], dtype=float32)])\n",
      "  -52.63603210449219]\n",
      " [list([array([-0.4699955,  0.       ], dtype=float32)]) 0 -1.0\n",
      "  list([array([-0.6213757 ,  0.01751898], dtype=float32)])\n",
      "  -52.63603210449219]\n",
      " [list([array([-0.4629486,  0.       ], dtype=float32)]) 0 -1.0\n",
      "  list([array([-0.66574067, -0.00623481], dtype=float32)])\n",
      "  -52.63603210449219]\n",
      " [list([array([-0.44839054,  0.        ], dtype=float32)]) 0 -1.0\n",
      "  list([array([-0.7238479 , -0.01189496], dtype=float32)])\n",
      "  -52.63603210449219]\n",
      " [list([array([-0.48909995,  0.        ], dtype=float32)]) 0 -1.0\n",
      "  list([array([-0.67136884, -0.00613037], dtype=float32)])\n",
      "  -52.63603210449219]\n",
      " [list([array([-0.43117407,  0.        ], dtype=float32)]) 0 -1.0\n",
      "  list([array([-0.60938543, -0.00515359], dtype=float32)])\n",
      "  -52.63603210449219]\n",
      " [list([array([-0.5026329,  0.       ], dtype=float32)]) 0 -1.0\n",
      "  list([array([-0.57016075, -0.01855586], dtype=float32)])\n",
      "  -52.63603210449219]\n",
      " [list([array([-0.48909995,  0.        ], dtype=float32)]) 0 -1.0\n",
      "  list([array([-0.7264866 ,  0.00282106], dtype=float32)])\n",
      "  -52.63603210449219]\n",
      " [list([array([-0.5463389,  0.       ], dtype=float32)]) 0 -1.0\n",
      "  list([array([-0.6501461 , -0.01828937], dtype=float32)])\n",
      "  -52.63603210449219]\n",
      " [list([array([-0.43677709,  0.        ], dtype=float32)]) 0 -1.0\n",
      "  list([array([-0.7176498 ,  0.01673359], dtype=float32)])\n",
      "  -52.63603210449219]\n",
      " [list([array([-0.54950947,  0.        ], dtype=float32)]) 0 -1.0\n",
      "  list([array([-0.81448704, -0.01046147], dtype=float32)])\n",
      "  -52.63603210449219]\n",
      " [list([array([-0.5987869,  0.       ], dtype=float32)]) 0 -1.0\n",
      "  list([array([-0.66461873, -0.00718579], dtype=float32)])\n",
      "  -52.63603210449219]\n",
      " [list([array([-0.4623231,  0.       ], dtype=float32)]) 0 -1.0\n",
      "  list([array([-0.7150815,  0.0075078], dtype=float32)])\n",
      "  -52.63603210449219]\n",
      " [list([array([-0.45796514,  0.        ], dtype=float32)]) 0 -1.0\n",
      "  list([array([-0.84591395,  0.00289452], dtype=float32)])\n",
      "  -52.63603210449219]\n",
      " [list([array([-0.5987869,  0.       ], dtype=float32)]) 0 -1.0\n",
      "  list([array([-0.7472368 , -0.00184519], dtype=float32)])\n",
      "  -52.63603210449219]\n",
      " [list([array([-0.4474817,  0.       ], dtype=float32)]) 0 -1.0\n",
      "  list([array([-0.55990887, -0.01062506], dtype=float32)])\n",
      "  -52.63603210449219]\n",
      " [list([array([-0.43117407,  0.        ], dtype=float32)]) 0 -1.0\n",
      "  list([array([-0.647513  ,  0.00680934], dtype=float32)])\n",
      "  -52.63603210449219]\n",
      " [list([array([-0.45153373,  0.        ], dtype=float32)]) 0 -1.0\n",
      "  list([array([-0.5365862 , -0.00317665], dtype=float32)])\n",
      "  -52.63603210449219]\n",
      " [list([array([-0.45796514,  0.        ], dtype=float32)]) 0 -1.0\n",
      "  list([array([-0.64759094, -0.01482227], dtype=float32)])\n",
      "  -52.63603210449219]\n",
      " [list([array([-0.45796514,  0.        ], dtype=float32)]) 0 -1.0\n",
      "  list([array([-0.52282387, -0.00875632], dtype=float32)])\n",
      "  -52.63603210449219]\n",
      " [list([array([-0.5552024,  0.       ], dtype=float32)]) 0 -1.0\n",
      "  list([array([-0.63286465,  0.00895951], dtype=float32)])\n",
      "  -52.370574951171875]\n",
      " [list([array([-0.5177686,  0.       ], dtype=float32)]) 0 -1.0\n",
      "  list([array([-0.61338   ,  0.01321321], dtype=float32)])\n",
      "  -52.63603210449219]\n",
      " [list([array([-0.4069218,  0.       ], dtype=float32)]) 0 -1.0\n",
      "  list([array([-0.774259  , -0.00155299], dtype=float32)])\n",
      "  -52.63603210449219]\n",
      " [list([array([-0.5177686,  0.       ], dtype=float32)]) 0 -1.0\n",
      "  list([array([-0.8125828 , -0.00684382], dtype=float32)])\n",
      "  -52.63603210449219]\n",
      " [list([array([-0.41626373,  0.        ], dtype=float32)]) 0 -1.0\n",
      "  list([array([-0.70918167, -0.00461906], dtype=float32)])\n",
      "  -52.63603210449219]\n",
      " [list([array([-0.5552024,  0.       ], dtype=float32)]) 0 -1.0\n",
      "  list([array([-0.53386605, -0.0050341 ], dtype=float32)])\n",
      "  -52.63603210449219]\n",
      " [list([array([-0.44839054,  0.        ], dtype=float32)]) 0 -1.0\n",
      "  list([array([-0.7176513 ,  0.00296856], dtype=float32)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -52.370574951171875]]\n"
     ]
    }
   ],
   "source": [
    "ql.test(\"MountainCar-v0\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
